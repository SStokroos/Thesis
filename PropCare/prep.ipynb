{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sten Stokroos\\AppData\\Local\\Temp\\ipykernel_24716\\3341867906.py\", line 9, in <module>\n",
      "    from simulator.data_generator_ml import DataGeneratorML\n",
      "  File \"c:\\Users\\Sten Stokroos\\OneDrive\\Bureaublad\\Master\\Thesis\\Code\\PropCare\\simulator\\data_generator_ml.py\", line 5, in <module>\n",
      "    from recommender.popular_base import PopularBase\n",
      "ImportError: cannot import name 'PopularBase' from 'recommender.popular_base' (c:\\Users\\Sten Stokroos\\OneDrive\\Bureaublad\\Master\\Thesis\\Code\\PropCare\\recommender\\popular_base.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\Sten Stokroos\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "random.seed(10)\n",
    "\n",
    "from simulator.data_generator_ml import DataGeneratorML\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "def setup_arg_parser():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='prepare_data_ml.py',\n",
    "        usage='prepare semi-synthetic data from movielens',\n",
    "        description='',\n",
    "        add_help=True)\n",
    "\n",
    "    parser.add_argument('-vml', '--version_of_movielens', type=str, default='100k',\n",
    "                        help='choose a version of movielens', required=False)\n",
    "    parser.add_argument('-crp', '--cond_rating_prediction', type=str,\n",
    "                        default='dim_factor:100+reg_factor:0.01+learn_rate:0.001+iter:100000000',\n",
    "                        help='condition of rating prediction')\n",
    "    parser.add_argument('-cwp', '--cond_watch_prediction', type=str,\n",
    "                        default='dim_factor:100+reg_factor:0.01+learn_rate:0.001+iter:100000000',\n",
    "                        help='condition of watch prediction')\n",
    "\n",
    "    parser.add_argument('-ora', '--offset_rating', type=float,\n",
    "                        default=5.0,\n",
    "                        help='offset of predicted rating when convert it to the outcome probability under treatement')\n",
    "    parser.add_argument('-scao', '--scaling_outcome', type=float,\n",
    "                        default=1.0,\n",
    "                        help='scaling of predicted watch when convert it to the outcome probability under control')\n",
    "    parser.add_argument('-scap', '--scaling_propensity', type=float,\n",
    "                        default=1.0,\n",
    "                        help='scaling of propensity when based on ranking')\n",
    "    parser.add_argument('-mas', '--mode_assignment', type=str,\n",
    "                        help='mode of treatment assignment', default='uniform',\n",
    "                        required=False)\n",
    "    parser.add_argument('-nr', '--num_rec', type=int,\n",
    "                        help='expected number of recommendation', default=210,\n",
    "                        required=False)\n",
    "    parser.add_argument('-cap', '--capping', type=float,\n",
    "                        help='capping', default=0.000001,\n",
    "                        required=False)\n",
    "\n",
    "    parser.add_argument('-nc', '--num_CPU', type=int, default=1,\n",
    "                        help='number of CPU used',\n",
    "                        required=False)\n",
    "    parser.add_argument('-ssr', '--set_seed_random', type=int, default=1,\n",
    "                        help='set seed for randomness',\n",
    "                        required=False)\n",
    "    parser.add_argument('-trt', '--trim_train_data', action='store_true',\n",
    "                        help='remove unpurchased and unrecommended for train data',\n",
    "                        required=False)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = setup_arg_parser()\n",
    "    np.random.seed(seed=args.set_seed_random)\n",
    "\n",
    "    dir_data_prepared = 'data/synthetic/ML_'+ args.version_of_movielens + '_' + args.mode_assignment + str(args.num_rec) \\\n",
    "                        + '_offset' + format(args.offset_rating, '.1f') + '_scaling' + format(args.scaling_propensity, '.1f') + '/'\n",
    "\n",
    "    print('dir_data_prepared is {}.'.format(dir_data_prepared))\n",
    "\n",
    "    if not os.path.exists(dir_data_prepared):\n",
    "        os.mkdir(dir_data_prepared)\n",
    "\n",
    "    print('mode_assignment is {}.'.format(args.mode_assignment))\n",
    "\n",
    "    print('Start prepare data.')\n",
    "    t_init = datetime.now()\n",
    "\n",
    "    os.environ['OMP_NUM_THREADS'] = str(args.num_CPU)\n",
    "    data_generator = DataGeneratorML()\n",
    "\n",
    "    # load movielens dataset (ML100K, ML25M, etc.)\n",
    "    data_generator.load_data(args.version_of_movielens)\n",
    "\n",
    "    # predict rating\n",
    "    cond_params = args.cond_rating_prediction.split('+')\n",
    "    dict_params = dict()\n",
    "    for cond_param in cond_params:\n",
    "        cond = cond_param.split(':')\n",
    "        dict_params[cond[0]] = cond[1]\n",
    "    data_generator.predict_rating(learn_rate=float(dict_params['learn_rate']), iter=int(dict_params['iter']),\n",
    "                                  dim_factor=int(dict_params['dim_factor']), reg_factor=float(dict_params['reg_factor']))\n",
    "\n",
    "    # predict observation\n",
    "    cond_params = args.cond_watch_prediction.split('+')\n",
    "    dict_params = dict()\n",
    "    for cond_param in cond_params:\n",
    "        cond = cond_param.split(':')\n",
    "        dict_params[cond[0]] = cond[1]\n",
    "    data_generator.predict_watch(learn_rate=float(dict_params['learn_rate']), iter=int(dict_params['iter']),\n",
    "                                  dim_factor=int(dict_params['dim_factor']), reg_factor=float(dict_params['reg_factor']))\n",
    "\n",
    "    # set ground truth probability\n",
    "    data_generator.set_prob_outcome_treated(offset=args.offset_rating)\n",
    "    data_generator.set_prob_outcome_control(scaling_outcome=args.scaling_outcome)\n",
    "\n",
    "    # set propensity\n",
    "    data_generator.assign_propensity(mode=args.mode_assignment, scaling_propensity=args.scaling_propensity,\n",
    "                                     num_rec=args.num_rec, capping=args.capping)\n",
    "\n",
    "    # generate recommendation\n",
    "    data_generator.assign_treatment()\n",
    "    # generate outcomes (potential and observed)\n",
    "    data_generator.assign_outcome()\n",
    "    # save data\n",
    "    if args.trim_train_data:\n",
    "        temp_bool = (data_generator.df_data.loc[:, 'treated'] + data_generator.df_data.loc[:, 'outcome']) > 0\n",
    "        df_data_train = data_generator.df_data.loc[temp_bool,:]\n",
    "        df_data_train.to_csv(dir_data_prepared + 'data_train.csv', index=False)\n",
    "    else:\n",
    "        data_generator.df_data.to_csv(dir_data_prepared + 'data_train.csv', index=False)\n",
    "\n",
    "    # vali\n",
    "    # generate recommendation\n",
    "    data_generator.assign_treatment()\n",
    "    # generate outcomes (potential and observed)\n",
    "    data_generator.assign_outcome()\n",
    "    # save data\n",
    "\n",
    "    data_generator.df_data.to_csv(dir_data_prepared + 'data_vali.csv', index=False)\n",
    "\n",
    "    # test\n",
    "    # generate recommendation\n",
    "    data_generator.assign_treatment()\n",
    "    # generate outcomes (potential and observed)\n",
    "    data_generator.assign_outcome()\n",
    "    # save data\n",
    "    data_generator.df_data.to_csv(dir_data_prepared + 'data_test.csv', index=False)\n",
    "\n",
    "    print('Data prepared.')\n",
    "    print('num_users: {}'.format(data_generator.num_users))\n",
    "    print('num_items: {}'.format(data_generator.num_items))\n",
    "    print('num_data: {}'.format(data_generator.num_data))\n",
    "    print(data_generator.df_data.info())\n",
    "\n",
    "    print('Max propensity: {}'.format(np.max(data_generator.df_data.loc[:, 'propensity'])))\n",
    "    print('Min propensity: {}'.format(np.min(data_generator.df_data.loc[:, 'propensity'])))\n",
    "    print('Average propensity: {}'.format(np.mean(data_generator.df_data.loc[:, 'propensity'])))\n",
    "    print('Average number of recommendations: {}'.format(np.mean(data_generator.df_data.loc[:, 'treated'])*data_generator.num_items))\n",
    "    print('Ratio of positive outcomes: {}'.format(np.mean(data_generator.df_data.loc[:, 'outcome'])))\n",
    "    print('Ratio of positive treatment effect: {}'.format(np.mean(data_generator.df_data.loc[:, 'causal_effect'] > 0)))\n",
    "    print('Ratio of negative treatment effect: {}'.format(np.mean(data_generator.df_data.loc[:, 'causal_effect'] < 0)))\n",
    "    print('Average treatment effect: {}'.format(np.mean(data_generator.df_data.loc[:, 'causal_effect'])))\n",
    "\n",
    "    t_end = datetime.now()\n",
    "    t_diff = t_end - t_init\n",
    "\n",
    "    hours = (t_diff.days * 24) + (t_diff.seconds / 3600)\n",
    "    print('Completed in {:.2f} hours.'.format(hours))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\sten stokroos\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten Stokroos\\OneDrive\\Bureaublad\\Master\\Thesis\\Code\\PropCare\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
